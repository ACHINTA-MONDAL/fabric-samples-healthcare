{"cells":[{"cell_type":"markdown","source":["### 01 - Download CMS Medicare Part D data files (CSV format) to Lakehouse\n","\n","- [CMS Medicare Part D Prescribers - by Provider and Drug](https://data.cms.gov/provider-summary-by-type-of-service/medicare-part-d-prescribers/medicare-part-d-prescribers-by-provider-and-drug) dataset is available for download from CMS Website. \n","- This Notebook use [Public API Open Data Catalog](https://data.cms.gov/data.json) metadata json file published by CMS to identify and download dataset files to the Lakehouse\n","- Dataset contains one file for each year, Title field available for each in Metadata json is used tor identity the year value. Example - Title \"Medicare Part D Prescribers - by Provider and Drug : 2016-12-31\" indicates the file is for the year 2016"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e179bf6f-ce5b-4063-892d-7448ee4f6b72"},{"cell_type":"code","source":["#create the sub-directory in Files folder where the CSV files will be downloaded\n","lakehouse_dir = \"Files/cms_raw\"\n","notebookutils.fs.mkdirs(lakehouse_dir)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"762a0349-842d-485b-8955-42a317e01c81"},{"cell_type":"code","source":["# Documentation provided at the following location  https://data.cms.gov/sites/default/files/2024-05/39b98adf-b5e0-4487-a19e-4dc5c1503d41/API%20Guide%20Formatted%201_5.pdf\n","# was used as basis for the following code which parses the Public API Open Data Catalog json file to identity the dataset files \n","\n","import requests\n","url = \"https://data.cms.gov/data.json\"\n","title= \"Medicare Part D Prescribers - by Provider and Drug\"\n","csv_distros =[]\n","response = requests.request(\"GET\", url)\n","\n","if response.ok:\n","    response = response.json()\n","    dataset = response['dataset']\n","    for set in dataset:\n","        if title == set['title']:\n","            for distro in set['distribution']:\n","                if 'mediaType' in distro.keys():\n","                    if distro['mediaType'] == \"text/csv\":\n","                        csv_distros.append(distro)        \n","else:\n","    error_message = f\"An error occrred in downloading the files from CMS Website: {response}\"\n","    print(error_message)\n","    notebookutils.notebook.exit(error_message, 1)\n","\n","#print(csv_distros)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2fc3ab1f-681a-469f-936b-08592e3d25f8"},{"cell_type":"code","source":["#create spark dataframe with rows for all files for the dataset\n","#downloadURL and title are the 2 fields of interest which are added as column in the dataframe\n","selected_dataset = [{\"downloadURL\": obj[\"downloadURL\"], \"title\": obj[\"title\"]} for obj in csv_distros]\n","df = spark.createDataFrame(selected_dataset)\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"0596f3f7-f570-490c-996c-2e474890779f"},{"cell_type":"code","source":["from pyspark.sql.functions import regexp_extract\n","\n","#identify Year value from the Title and add that as a column to dataframe\n","df = df.withColumn(\"year\", regexp_extract(\"title\", r\"(\\d{4})\", 1))\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"36c20ad6-1514-4170-9b50-a7ab3e944fda"},{"cell_type":"code","source":["#function to download the file from URL\n","def download_file(url, filename):\n","    response = requests.get(url)    \n","    with open(filename, 'wb') as file:\n","        file.write(response.content)\n","\n","#function to process each DataFrame Row which corresponds to single file in teh dataset\n","#downloaded file is named based on the year value associated with data\n","def process_partition(partition):\n","    for row in partition:\n","        year_value = row['year']\n","        output_file = \"/lakehouse/default/\" + lakehouse_dir + \"/\" + row['year'] + \".csv\"\n","        download_file(row['downloadURL'], output_file)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"155738ee-aa7a-4aeb-8fff-9bc140ebe7eb"},{"cell_type":"code","source":["#process the dataframe where each row represents a file to be downloaded from CMS file\n","df.rdd.foreachPartition(process_partition)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"77628dc7-17a0-4061-94d1-527d91423819"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{"default_lakehouse":"96391b77-cc32-4714-b791-70a15ccc429f","known_lakehouses":[{"id":"96391b77-cc32-4714-b791-70a15ccc429f"}],"default_lakehouse_name":"cmsrawlh1","default_lakehouse_workspace_id":"f16554c0-3959-4537-9128-ad08c6ac1692"}}},"nbformat":4,"nbformat_minor":5}